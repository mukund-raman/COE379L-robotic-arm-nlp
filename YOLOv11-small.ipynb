{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee538be7-4035-4216-b6e0-26d03b9bc5d3",
   "metadata": {},
   "source": [
    "# Candy Detection Model from Edje Electronics Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b068f4-a61b-46ca-a99d-85e9bc31147e",
   "metadata": {},
   "source": [
    "### Split the candy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0505c491-dba8-4021-b28d-e8516adb201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8266c527-f368-4ebb-bc98-57d5dc74bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove existing train/test directories if necessary\n",
    "try: \n",
    "    shutil.rmtree('data/candy-split/train')\n",
    "    shutil.rmtree('data/candy-split/train')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create train directories for images\n",
    "Path('data/candy-split/train').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/candy-split/train/images').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/candy-split/train/labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create test directories for images\n",
    "Path('data/candy-split/test').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/candy-split/test/images').mkdir(parents=True, exist_ok=True)\n",
    "Path('data/candy-split/test/labels').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f91f396-4888-4804-887e-a8b2c3fddd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: 162\n",
      "Number of annotation files: 162\n"
     ]
    }
   ],
   "source": [
    "# Define path to input dataset\n",
    "data_path = './data/candy_data_06JAN25/'\n",
    "input_image_path = os.path.join(data_path, 'images')\n",
    "input_label_path = os.path.join(data_path, 'labels')\n",
    "# print(input_image_path)\n",
    "# print(input_label_path)\n",
    "\n",
    "# Define paths to image and annotation folders\n",
    "cwd = os.getcwd()\n",
    "train_img_path = os.path.join(cwd,'data/candy-split/train/images')\n",
    "train_txt_path = os.path.join(cwd,'data/candy-split/train/labels')\n",
    "test_img_path = os.path.join(cwd,'data/candy-split/test/images')\n",
    "test_txt_path = os.path.join(cwd,'data/candy-split/test/labels')\n",
    "# print(train_img_path)\n",
    "\n",
    "# Get list of all images and annotation files\n",
    "img_file_list = [path for path in Path(input_image_path).rglob('*')]\n",
    "txt_file_list = [path for path in Path(input_label_path).rglob('*')]\n",
    "\n",
    "print(f'Number of image files: {len(img_file_list)}')\n",
    "print(f'Number of annotation files: {len(txt_file_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0008ad2-fcbd-4644-8c9a-6a4e44d8f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images moving to train: 129\n",
      "Imgaes moving to test: 33\n"
     ]
    }
   ],
   "source": [
    "# Determine number of files to move to each folder\n",
    "file_num = len(img_file_list)\n",
    "train_percent = 0.80\n",
    "train_num = int(file_num*train_percent)\n",
    "test_num = file_num - train_num\n",
    "print('Images moving to train: %d' % train_num)\n",
    "print('Imgaes moving to test: %d' % test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d917ee7-40ae-4538-8c70-81e5e225e25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select files randomly and more to train to test\n",
    "for i, set_num in enumerate([train_num, test_num]):\n",
    "    for ii in range(set_num):\n",
    "        img_path = random.choice(img_file_list)\n",
    "        img_fn = img_path.name\n",
    "        base_fn = img_path.stem\n",
    "        txt_fn = base_fn + '.txt'\n",
    "        txt_path = os.path.join(input_label_path, txt_fn)\n",
    "\n",
    "        if i == 0: # Copy first set of files to train folders\n",
    "            new_img_path, new_txt_path = train_img_path, train_txt_path\n",
    "        elif i == 1: # Copy second set of files to the validation folders\n",
    "            new_img_path, new_txt_path = test_img_path, test_txt_path\n",
    "\n",
    "        shutil.copy(img_path, os.path.join(new_img_path, img_fn))\n",
    "        # If txt path does not exist, this is a background image, so skip txt file\n",
    "        if os.path.exists(txt_path):\n",
    "            shutil.copy(txt_path, os.path.join(new_txt_path, txt_fn))\n",
    "\n",
    "        img_file_list.remove(img_path)\n",
    "                        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ea611-27d0-41a9-bf49-27939993b30a",
   "metadata": {},
   "source": [
    "### Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d321725-715a-4aac-bc5b-411dd9b43f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo detect train data=data.yaml model=yolo11s.pt epochs=60 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78c4d1-22dc-4b4c-978b-af6107f41a97",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e039c3-8466-4a0e-bed6-2f9721ed6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57902f60-f038-45fb-8b13-d173acc7546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './runs/detect/train/weights/best.pt'\n",
    "img_source = './data/candy-test/testvid.mp4'\n",
    "# min_thresh = \n",
    "user_res = '1280x720'\n",
    "record = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46d0a2e-748d-413d-92c1-5c93cc196f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.exists(model_path)):\n",
    "    print('ERROR: Model path is invalid or model was not found. Make sure the model filename was entered correctly.')\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    print('Model found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce18a08d-1b86-4311-bea9-82797278666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path, task='detect')\n",
    "labels = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c62c31-b30a-4fa7-bd8a-27a530dcb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse input to determine if image source is a file, folder, video, or USB camera\n",
    "img_ext_list = ['.jpg','.JPG','.jpeg','.JPEG','.png','.PNG','.bmp','.BMP']\n",
    "vid_ext_list = ['.avi','.mov','.mp4','.mkv','.wmv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8c9fc0-312d-4e11-86ba-b9b2a2768f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(img_source):\n",
    "    source_type = 'folder'\n",
    "elif os.path.isfile(img_source):\n",
    "    _, ext = os.path.splitext(img_source)\n",
    "    if ext in img_ext_list:\n",
    "        source_type = 'image'\n",
    "    elif ext in vid_ext_list:\n",
    "        source_type = 'video'\n",
    "    else:\n",
    "        print(f'File extension {ext} is not supported.')\n",
    "        sys.exit(0)\n",
    "elif 'usb' in img_source:\n",
    "    source_type = 'usb'\n",
    "    usb_idx = int(img_source[3:])\n",
    "elif 'picamera' in img_source:\n",
    "    source_type = 'picamera'\n",
    "    picam_idx = int(img_source[8:])\n",
    "else:\n",
    "    print(f'Input {img_source} is invalid. Please try again.')\n",
    "    sys.exit(0)\n",
    "\n",
    "print(source_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f1e69f5-1590-4254-8dfa-cdbb98682fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "# Parse user-specified display resolution\n",
    "resize = False\n",
    "if user_res:\n",
    "    resize = True\n",
    "    resW, resH = int(user_res.split('x')[0]), int(user_res.split('x')[1])\n",
    "\n",
    "print(resW, resH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8217a29d-c75c-46c5-a368-045385d698fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if recording is valid and set up recording\n",
    "if record:\n",
    "    if source_type not in ['video','usb']:\n",
    "        print('Recording only works for video and camera sources. Please try again.')\n",
    "        sys.exit(0)\n",
    "    if not user_res:\n",
    "        print('Please specify resolution to record video at.')\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # Set up recording\n",
    "    record_name = 'demo1.avi'\n",
    "    record_fps = 30\n",
    "    recorder = cv2.VideoWriter(record_name, cv2.VideoWriter_fourcc(*'MJPG'), record_fps, (resW,resH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd4ff03a-296b-4f33-a2ea-6d8a3a64c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize image source\n",
    "if source_type == 'image':\n",
    "    imgs_list = [img_source]\n",
    "elif source_type == 'folder':\n",
    "    imgs_list = []\n",
    "    filelist = glob.glob(img_source + '/*')\n",
    "    for file in filelist:\n",
    "        _, file_ext = os.path.splitext(file)\n",
    "        if file_ext in img_ext_list:\n",
    "            imgs_list.append(file)\n",
    "elif source_type == 'video' or source_type == 'usb':\n",
    "\n",
    "    if source_type == 'video': cap_arg = img_source\n",
    "    elif source_type == 'usb': cap_arg = usb_idx\n",
    "    cap = cv2.VideoCapture(cap_arg)\n",
    "\n",
    "    # Set camera or video resolution if specified by user\n",
    "    if user_res:\n",
    "        ret = cap.set(3, resW)\n",
    "        ret = cap.set(4, resH)\n",
    "\n",
    "elif source_type == 'picamera':\n",
    "    from picamera2 import Picamera2\n",
    "    cap = Picamera2()\n",
    "    cap.configure(cap.create_video_configuration(main={\"format\": 'RGB888', \"size\": (resW, resH)}))\n",
    "    cap.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61003b78-6055-488e-9675-af66a4db5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bounding box colors (using the Tableu 10 color scheme)\n",
    "bbox_colors = [(164,120,87), (68,148,228), (93,97,209), (178,182,133), (88,159,106), \n",
    "              (96,202,231), (159,124,168), (169,162,241), (98,118,150), (172,176,184)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d45f85a-5b50-45a0-9115-d65064f3bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize control and status variables\n",
    "avg_frame_rate = 0\n",
    "frame_rate_buffer = []\n",
    "fps_avg_len = 200\n",
    "img_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "485cde01-eb78-466d-ae31-3a70d9f7043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached end of the video file. Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# Define the video codec and create a VideoWriter object\n",
    "output_path = 'output_video.avi'  # Set your desired output path and filename\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Choose codec (e.g., XVID, MJPG)\n",
    "fps = 20  # Set frames per second (adjust to your needs)\n",
    "\n",
    "# Create VideoWriter object\n",
    "recorder = cv2.VideoWriter(output_path, fourcc, fps, (resW, resH))\n",
    "\n",
    "# Begin inference loop\n",
    "while True:\n",
    "\n",
    "    t_start = time.perf_counter()\n",
    "    # Load frame from image source\n",
    "    if source_type == 'image' or source_type == 'folder': # If source is image or image folder, load the image using its filename\n",
    "        if img_count >= len(imgs_list):\n",
    "            print('All images have been processed. Exiting program.')\n",
    "            sys.exit(0)\n",
    "        img_filename = imgs_list[img_count]\n",
    "        frame = cv2.imread(img_filename)\n",
    "        img_count = img_count + 1\n",
    "    \n",
    "    elif source_type == 'video': # If source is a video, load next frame from video file\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Reached end of the video file. Exiting program.')\n",
    "            break\n",
    "    \n",
    "    elif source_type == 'usb': # If source is a USB camera, grab frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        if (frame is None) or (not ret):\n",
    "            print('Unable to read frames from the camera. This indicates the camera is disconnected or not working. Exiting program.')\n",
    "            break\n",
    "\n",
    "    elif source_type == 'picamera': # If source is a Picamera, grab frames using picamera interface\n",
    "        frame = cap.capture_array()\n",
    "        if (frame is None):\n",
    "            print('Unable to read frames from the Picamera. This indicates the camera is disconnected or not working. Exiting program.')\n",
    "            break\n",
    "\n",
    "    # Resize frame to desired display resolution\n",
    "    if resize == True:\n",
    "        frame = cv2.resize(frame,(resW,resH))\n",
    "\n",
    "    # Run inference on frame\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # Extract results\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    # Initialize variable for basic object counting example\n",
    "    object_count = 0\n",
    "\n",
    "    # Go through each detection and get bbox coords, confidence, and class\n",
    "    for i in range(len(detections)):\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        # Ultralytics returns results in Tensor format, which have to be converted to a regular Python array\n",
    "        xyxy_tensor = detections[i].xyxy.cpu() # Detections in Tensor format in CPU memory\n",
    "        xyxy = xyxy_tensor.numpy().squeeze() # Convert tensors to Numpy array\n",
    "        xmin, ymin, xmax, ymax = xyxy.astype(int) # Extract individual coordinates and convert to int\n",
    "\n",
    "        # Get bounding box class ID and name\n",
    "        classidx = int(detections[i].cls.item())\n",
    "        classname = labels[classidx]\n",
    "\n",
    "        # Get bounding box confidence\n",
    "        conf = detections[i].conf.item()\n",
    "\n",
    "        # Draw box if confidence threshold is high enough\n",
    "        if conf > 0.5:\n",
    "\n",
    "            color = bbox_colors[classidx % 10]\n",
    "            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), color, 2)\n",
    "\n",
    "            label = f'{classname}: {int(conf*100)}%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1) # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), color, cv2.FILLED) # Draw white box to put label text in\n",
    "            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1) # Draw label text\n",
    "\n",
    "            # Basic example: count the number of objects in the image\n",
    "            object_count = object_count + 1\n",
    "\n",
    "    # Calculate and draw framerate (if using video, USB, or Picamera source)\n",
    "    if source_type == 'video' or source_type == 'usb' or source_type == 'picamera':\n",
    "        cv2.putText(frame, f'FPS: {avg_frame_rate:0.2f}', (10,20), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,255,255), 2) # Draw framerate\n",
    "    \n",
    "    # # Display detection results\n",
    "    # cv2.putText(frame, f'Number of objects: {object_count}', (10,40), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,255,255), 2) # Draw total number of detected objects\n",
    "    # cv2.imshow('YOLO detection results',frame) # Display image\n",
    "    # if record: recorder.write(frame)\n",
    "\n",
    "    # If inferencing on individual images, wait for user keypress before moving to next image. Otherwise, wait 5ms before moving to next frame.\n",
    "    if source_type == 'image' or source_type == 'folder':\n",
    "        key = cv2.waitKey()\n",
    "    elif source_type == 'video' or source_type == 'usb' or source_type == 'picamera':\n",
    "        key = cv2.waitKey(5)\n",
    "    \n",
    "    if key == ord('q') or key == ord('Q'): # Press 'q' to quit\n",
    "        break\n",
    "    elif key == ord('s') or key == ord('S'): # Press 's' to pause inference\n",
    "        cv2.waitKey()\n",
    "    elif key == ord('p') or key == ord('P'): # Press 'p' to save a picture of results on this frame\n",
    "        cv2.imwrite('capture.png',frame)\n",
    "    \n",
    "    # Calculate FPS for this frame\n",
    "    t_stop = time.perf_counter()\n",
    "    frame_rate_calc = float(1/(t_stop - t_start))\n",
    "\n",
    "    # Append FPS result to frame_rate_buffer (for finding average FPS over multiple frames)\n",
    "    if len(frame_rate_buffer) >= fps_avg_len:\n",
    "        temp = frame_rate_buffer.pop(0)\n",
    "        frame_rate_buffer.append(frame_rate_calc)\n",
    "    else:\n",
    "        frame_rate_buffer.append(frame_rate_calc)\n",
    "\n",
    "    # Calculate average FPS for past frames\n",
    "    avg_frame_rate = np.mean(frame_rate_buffer)\n",
    "\n",
    "    if record:\n",
    "        recorder.write(frame)\n",
    "\n",
    "recorder.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e5fa22a-f541-4a57-8652-83ee0748d5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pipeline FPS: 9.44\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "print(f'Average pipeline FPS: {avg_frame_rate:.2f}')\n",
    "if source_type == 'video' or source_type == 'usb':\n",
    "    cap.release()\n",
    "elif source_type == 'picamera':\n",
    "    cap.stop()\n",
    "if record: recorder.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
