{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee538be7-4035-4216-b6e0-26d03b9bc5d3",
   "metadata": {},
   "source": [
    "# YOLOv11-Small Model Image Classification\n",
    "Based on Edje Electronics' YOLO Tutorial:\n",
    "###### https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b068f4-a61b-46ca-a99d-85e9bc31147e",
   "metadata": {},
   "source": [
    "### Split the dataset\n",
    "Use the functions defined in `../data/data_splitter.py` to randomly split the given dataset into 80% for training and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0505c491-dba8-4021-b28d-e8516adb201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image files: 162\n",
      "Number of annotation files: 162\n",
      "Images moving to train: 129\n",
      "Images moving to test: 33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import data.data_splitter as ds\n",
    "data_dir = '../data/candy_data_06JAN25'\n",
    "ds.split_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ea611-27d0-41a9-bf49-27939993b30a",
   "metadata": {},
   "source": [
    "### Configure Model Training and Validation\n",
    "Use the function defined in `../data/data_yaml_generator.py` to create the YAML data file for training and the `yolo detect {train/predict}` function given by Ultralytics for training and validating the YOLOv11 model on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d321725-715a-4aac-bc5b-411dd9b43f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created config file at ../data/data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create a YAML configuration file for YOLO\n",
    "import data.data_yaml_generator as dyg\n",
    "yaml_file = '../data/data.yaml'\n",
    "classes_file = f'{data_dir}-split/classes.txt'\n",
    "dyg.create_data_yaml(classes_file, yaml_file)\n",
    "\n",
    "# Train the model using the YAML configuration file and YOLO model\n",
    "RETRAIN_MODEL = False\n",
    "if RETRAIN_MODEL or not os.path.exists('yolo11s.pt'):\n",
    "    subprocess.run([\n",
    "        \"yolo\", \"detect\", \"train\",\n",
    "        f\"data={yaml_file}\",\n",
    "        \"model=yolo11s.pt\",\n",
    "        \"epochs=60\",\n",
    "        \"imgsz=640\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37eb079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.126 ðŸš€ Python-3.12.9 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4090, 24077MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,417,057 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\n",
      "image 1/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/0807ca73-candy_104.jpg: 480x640 1 MMs_regular, 2 airheadss, 1 gummy_worms, 1 snickers, 1 twizzlers, 22.6ms\n",
      "image 2/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/09f85b64-candy_19.jpg: 384x640 2 airheadss, 1 gummy_worms, 1 skittles, 1 three_musketeers, 22.4ms\n",
      "image 3/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/0d5743ea-candy_110.jpg: 480x640 2 airheadss, 2 gummy_wormss, 1 skittles, 2.1ms\n",
      "image 4/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/1600f5b1-candy_94.jpg: 480x640 2 milky_ways, 1 skittles, 1.8ms\n",
      "image 5/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/1a0a0a87-candy_138.jpg: 384x640 1 MMs_peanut, 2.0ms\n",
      "image 6/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/1a146567-candy_107.jpg: 480x640 1 MMs_peanut, 1 MMs_regular, 1 milky_way, 1 skittles, 1 twizzlers, 2.0ms\n",
      "image 7/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/36b46b7d-candy_98.jpg: 480x640 1 MMs_regular, 1 airheads, 1 gummy_worms, 1 skittles, 1 snickers, 1 three_musketeers, 1.8ms\n",
      "image 8/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/426f5963-candy_45.jpg: 384x640 1 MMs_peanut, 1 MMs_regular, 1 airheads, 1 milky_way, 1 snickers, 2.0ms\n",
      "image 9/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/48402bcc-candy_39.jpg: 384x640 2 MMs_peanuts, 2 MMs_regulars, 1 airheads, 1 gummy_worms, 1 milky_way, 3 twizzlerss, 1.8ms\n",
      "image 10/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/6580d01b-candy_116.jpg: 384x640 1 MMs_peanut, 1.9ms\n",
      "image 11/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/7058d4d5-candy_102.jpg: 480x640 1 MMs_peanut, 1 MMs_regular, 1 airheads, 1 gummy_worms, 1 milky_way, 1 twizzlers, 2.0ms\n",
      "image 12/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/7147c466-candy_68.jpg: 480x640 1 MMs_peanut, 1 MMs_regular, 2 airheadss, 1 snickers, 1 three_musketeers, 1.8ms\n",
      "image 13/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/73a058b9-candy_143.jpg: 384x640 1 milky_way, 1 starburst, 2.0ms\n",
      "image 14/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/7adca169-candy_108.jpg: 480x640 1 airheads, 2 starbursts, 1 three_musketeers, 1.9ms\n",
      "image 15/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/7cf835e4-candy_96.jpg: 480x640 1 MMs_peanut, 2 airheadss, 1 nerds, 1 starburst, 1 three_musketeers, 1 twizzlers, 1.8ms\n",
      "image 16/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/7e893c2d-candy_38.jpg: 384x640 2 MMs_peanuts, 2 MMs_regulars, 1 airheads, 1 gummy_worms, 1 milky_way, 2 twizzlerss, 2.0ms\n",
      "image 17/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/8243fdc5-candy_13.jpg: 384x640 1 MMs_regular, 2 airheadss, 1 twizzlers, 1.9ms\n",
      "image 18/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/84892ac0-candy_122.jpg: 384x640 1 airheads, 1.8ms\n",
      "image 19/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/911495c1-candy_88.jpg: 480x640 1 nerds, 1 skittles, 1 snickers, 2.0ms\n",
      "image 20/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/9d14fba0-candy_160.jpg: 384x640 1 twizzlers, 1.9ms\n",
      "image 21/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/b607895c-candy_144.jpg: 384x640 1 airheads, 1.8ms\n",
      "image 22/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/b6d1ec80-candy_149.jpg: 384x640 1 MMs_peanut, 1.8ms\n",
      "image 23/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/b768e6e3-candy_42.jpg: 384x640 1 MMs_peanut, 2 airheadss, 1 nerds, 1 skittles, 2 starbursts, 1 twizzlers, 1.8ms\n",
      "image 24/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/bf81e561-candy_28.jpg: 384x640 1 airheads, 1 gummy_worms, 1 milky_way, 1 nerds, 1 starburst, 1 three_musketeers, 1 twizzlers, 2.0ms\n",
      "image 25/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/c805fd30-candy_142.jpg: 384x640 1 milky_way, 1 starburst, 1.9ms\n",
      "image 26/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/ca9319cb-candy_23.jpg: 384x640 1 MMs_peanut, 1 airheads, 1 nerds, 1 three_musketeers, 1.9ms\n",
      "image 27/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/e4becfac-candy_153.jpg: 384x640 1 nerds, 1.8ms\n",
      "image 28/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/ec6af885-candy_137.jpg: 384x640 1 snickers, 2.0ms\n",
      "image 29/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/edb76969-candy_81.jpg: 480x640 3 airheadss, 1 starburst, 1 twizzlers, 2.0ms\n",
      "image 30/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/f18d33b1-candy_152.jpg: 384x640 1 nerds, 2.0ms\n",
      "image 31/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/fa57985d-candy_114.jpg: 480x640 1 MMs_peanut, 1 MMs_regular, 1 milky_way, 1 skittles, 1 twizzlers, 1.9ms\n",
      "image 32/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/faab64dc-candy_37.jpg: 384x640 2 MMs_regulars, 1 gummy_worms, 1 milky_way, 1 twizzlers, 2.0ms\n",
      "image 33/33 /home/motionprediction/.vscode/extensions/COE379L-robotic-arm-nlp/training/../data/candy_data_06JAN25-split/test/images/fe8defd2-candy_20.jpg: 384x640 1 airheads, 1 nerds, 1 starburst, 2.0ms\n",
      "Speed: 0.6ms preprocess, 3.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['yolo', 'detect', 'predict', 'model=runs/detect/train16/weights/best.pt', 'source=../data/candy_data_06JAN25-split/test/images', 'save=True'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_path = 'runs/detect/train16/weights/best.pt'\n",
    "subprocess.run([\n",
    "    \"yolo\", \"detect\", \"predict\",\n",
    "    f\"model={model_path}\",\n",
    "    f\"source={data_dir}-split/test/images\",\n",
    "    \"save=True\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78c4d1-22dc-4b4c-978b-af6107f41a97",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e039c3-8466-4a0e-bed6-2f9721ed6d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57902f60-f038-45fb-8b13-d173acc7546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './runs/detect/train16/weights/best.pt'\n",
    "img_source = f'{data_dir}-test/testvid.mp4'\n",
    "# min_thresh = \n",
    "user_res = '1280x720'\n",
    "record = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46d0a2e-748d-413d-92c1-5c93cc196f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found\n"
     ]
    }
   ],
   "source": [
    "if (not os.path.exists(model_path)):\n",
    "    print('ERROR: Model path is invalid or model was not found. Make sure the model filename was entered correctly.')\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    print('Model found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce18a08d-1b86-4311-bea9-82797278666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path, task='detect')\n",
    "labels = model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c62c31-b30a-4fa7-bd8a-27a530dcb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse input to determine if image source is a file, folder, video, or USB camera\n",
    "img_ext_list = ['.jpg','.JPG','.jpeg','.JPEG','.png','.PNG','.bmp','.BMP']\n",
    "vid_ext_list = ['.avi','.mov','.mp4','.mkv','.wmv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8c9fc0-312d-4e11-86ba-b9b2a2768f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(img_source):\n",
    "    source_type = 'folder'\n",
    "elif os.path.isfile(img_source):\n",
    "    _, ext = os.path.splitext(img_source)\n",
    "    if ext in img_ext_list:\n",
    "        source_type = 'image'\n",
    "    elif ext in vid_ext_list:\n",
    "        source_type = 'video'\n",
    "    else:\n",
    "        print(f'File extension {ext} is not supported.')\n",
    "        sys.exit(0)\n",
    "elif 'usb' in img_source:\n",
    "    source_type = 'usb'\n",
    "    usb_idx = int(img_source[3:])\n",
    "elif 'picamera' in img_source:\n",
    "    source_type = 'picamera'\n",
    "    picam_idx = int(img_source[8:])\n",
    "else:\n",
    "    print(f'Input {img_source} is invalid. Please try again.')\n",
    "    sys.exit(0)\n",
    "\n",
    "print(source_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f1e69f5-1590-4254-8dfa-cdbb98682fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280 720\n"
     ]
    }
   ],
   "source": [
    "# Parse user-specified display resolution\n",
    "resize = False\n",
    "if user_res:\n",
    "    resize = True\n",
    "    resW, resH = int(user_res.split('x')[0]), int(user_res.split('x')[1])\n",
    "\n",
    "print(resW, resH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8217a29d-c75c-46c5-a368-045385d698fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if recording is valid and set up recording\n",
    "if record:\n",
    "    if source_type not in ['video','usb']:\n",
    "        print('Recording only works for video and camera sources. Please try again.')\n",
    "        sys.exit(0)\n",
    "    if not user_res:\n",
    "        print('Please specify resolution to record video at.')\n",
    "        sys.exit(0)\n",
    "    \n",
    "    # Set up recording\n",
    "    record_name = 'demo1.avi'\n",
    "    record_fps = 30\n",
    "    recorder = cv2.VideoWriter(record_name, cv2.VideoWriter_fourcc(*'MJPG'), record_fps, (resW,resH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4ff03a-296b-4f33-a2ea-6d8a3a64c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or initialize image source\n",
    "if source_type == 'image':\n",
    "    imgs_list = [img_source]\n",
    "elif source_type == 'folder':\n",
    "    imgs_list = []\n",
    "    filelist = glob.glob(img_source + '/*')\n",
    "    for file in filelist:\n",
    "        _, file_ext = os.path.splitext(file)\n",
    "        if file_ext in img_ext_list:\n",
    "            imgs_list.append(file)\n",
    "elif source_type == 'video' or source_type == 'usb':\n",
    "    if source_type == 'video': cap_arg = img_source\n",
    "    elif source_type == 'usb': cap_arg = usb_idx\n",
    "    cap = cv2.VideoCapture(cap_arg)\n",
    "\n",
    "    # Set camera or video resolution if specified by user\n",
    "    if user_res:\n",
    "        ret = cap.set(3, resW)\n",
    "        ret = cap.set(4, resH)\n",
    "elif source_type == 'picamera':\n",
    "    from picamera2 import Picamera2\n",
    "    cap = Picamera2()\n",
    "    cap.configure(cap.create_video_configuration(main={\"format\": 'RGB888', \"size\": (resW, resH)}))\n",
    "    cap.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61003b78-6055-488e-9675-af66a4db5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set bounding box colors (using the Tableu 10 color scheme)\n",
    "bbox_colors = [(164,120,87), (68,148,228), (93,97,209), (178,182,133), (88,159,106), \n",
    "              (96,202,231), (159,124,168), (169,162,241), (98,118,150), (172,176,184)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d45f85a-5b50-45a0-9115-d65064f3bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize control and status variables\n",
    "avg_frame_rate = 0\n",
    "frame_rate_buffer = []\n",
    "fps_avg_len = 200\n",
    "img_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "485cde01-eb78-466d-ae31-3a70d9f7043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached end of the video file. Exiting program.\n"
     ]
    }
   ],
   "source": [
    "# Define the video codec and create a VideoWriter object\n",
    "output_path = 'output_video.avi'  # Set your desired output path and filename\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Choose codec (e.g., XVID, MJPG)\n",
    "fps = 20  # Set frames per second (adjust to your needs)\n",
    "\n",
    "# Create VideoWriter object\n",
    "recorder = cv2.VideoWriter(output_path, fourcc, fps, (resW, resH))\n",
    "\n",
    "# Begin inference loop\n",
    "while True:\n",
    "\n",
    "    t_start = time.perf_counter()\n",
    "    # Load frame from image source\n",
    "    if source_type == 'image' or source_type == 'folder': # If source is image or image folder, load the image using its filename\n",
    "        if img_count >= len(imgs_list):\n",
    "            print('All images have been processed. Exiting program.')\n",
    "            sys.exit(0)\n",
    "        img_filename = imgs_list[img_count]\n",
    "        frame = cv2.imread(img_filename)\n",
    "        img_count = img_count + 1\n",
    "    \n",
    "    elif source_type == 'video': # If source is a video, load next frame from video file\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Reached end of the video file. Exiting program.')\n",
    "            break\n",
    "    \n",
    "    elif source_type == 'usb': # If source is a USB camera, grab frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        if (frame is None) or (not ret):\n",
    "            print('Unable to read frames from the camera. This indicates the camera is disconnected or not working. Exiting program.')\n",
    "            break\n",
    "\n",
    "    elif source_type == 'picamera': # If source is a Picamera, grab frames using picamera interface\n",
    "        frame = cap.capture_array()\n",
    "        if (frame is None):\n",
    "            print('Unable to read frames from the Picamera. This indicates the camera is disconnected or not working. Exiting program.')\n",
    "            break\n",
    "\n",
    "    # Resize frame to desired display resolution\n",
    "    if resize == True:\n",
    "        frame = cv2.resize(frame,(resW,resH))\n",
    "\n",
    "    # Run inference on frame\n",
    "    results = model(frame, verbose=False)\n",
    "\n",
    "    # Extract results\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    # Initialize variable for basic object counting example\n",
    "    object_count = 0\n",
    "\n",
    "    # Go through each detection and get bbox coords, confidence, and class\n",
    "    for i in range(len(detections)):\n",
    "\n",
    "        # Get bounding box coordinates\n",
    "        # Ultralytics returns results in Tensor format, which have to be converted to a regular Python array\n",
    "        xyxy_tensor = detections[i].xyxy.cpu() # Detections in Tensor format in CPU memory\n",
    "        xyxy = xyxy_tensor.numpy().squeeze() # Convert tensors to Numpy array\n",
    "        xmin, ymin, xmax, ymax = xyxy.astype(int) # Extract individual coordinates and convert to int\n",
    "\n",
    "        # Get bounding box class ID and name\n",
    "        classidx = int(detections[i].cls.item())\n",
    "        classname = labels[classidx]\n",
    "\n",
    "        # Get bounding box confidence\n",
    "        conf = detections[i].conf.item()\n",
    "\n",
    "        # Draw box if confidence threshold is high enough\n",
    "        if conf > 0.5:\n",
    "\n",
    "            color = bbox_colors[classidx % 10]\n",
    "            cv2.rectangle(frame, (xmin,ymin), (xmax,ymax), color, 2)\n",
    "\n",
    "            label = f'{classname}: {int(conf*100)}%'\n",
    "            labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1) # Get font size\n",
    "            label_ymin = max(ymin, labelSize[1] + 10) # Make sure not to draw label too close to top of window\n",
    "            cv2.rectangle(frame, (xmin, label_ymin-labelSize[1]-10), (xmin+labelSize[0], label_ymin+baseLine-10), color, cv2.FILLED) # Draw white box to put label text in\n",
    "            cv2.putText(frame, label, (xmin, label_ymin-7), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1) # Draw label text\n",
    "\n",
    "            # Basic example: count the number of objects in the image\n",
    "            object_count = object_count + 1\n",
    "\n",
    "    # Calculate and draw framerate (if using video, USB, or Picamera source)\n",
    "    if source_type == 'video' or source_type == 'usb' or source_type == 'picamera':\n",
    "        cv2.putText(frame, f'FPS: {avg_frame_rate:0.2f}', (10,20), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,255,255), 2) # Draw framerate\n",
    "    \n",
    "    # # Display detection results\n",
    "    # cv2.putText(frame, f'Number of objects: {object_count}', (10,40), cv2.FONT_HERSHEY_SIMPLEX, .7, (0,255,255), 2) # Draw total number of detected objects\n",
    "    # cv2.imshow('YOLO detection results',frame) # Display image\n",
    "    # if record: recorder.write(frame)\n",
    "\n",
    "    # If inferencing on individual images, wait for user keypress before moving to next image. Otherwise, wait 5ms before moving to next frame.\n",
    "    if source_type == 'image' or source_type == 'folder':\n",
    "        key = cv2.waitKey()\n",
    "    elif source_type == 'video' or source_type == 'usb' or source_type == 'picamera':\n",
    "        key = cv2.waitKey(5)\n",
    "    \n",
    "    if key == ord('q') or key == ord('Q'): # Press 'q' to quit\n",
    "        break\n",
    "    elif key == ord('s') or key == ord('S'): # Press 's' to pause inference\n",
    "        cv2.waitKey()\n",
    "    elif key == ord('p') or key == ord('P'): # Press 'p' to save a picture of results on this frame\n",
    "        cv2.imwrite('capture.png',frame)\n",
    "    \n",
    "    # Calculate FPS for this frame\n",
    "    t_stop = time.perf_counter()\n",
    "    frame_rate_calc = float(1/(t_stop - t_start))\n",
    "\n",
    "    # Append FPS result to frame_rate_buffer (for finding average FPS over multiple frames)\n",
    "    if len(frame_rate_buffer) >= fps_avg_len:\n",
    "        temp = frame_rate_buffer.pop(0)\n",
    "        frame_rate_buffer.append(frame_rate_calc)\n",
    "    else:\n",
    "        frame_rate_buffer.append(frame_rate_calc)\n",
    "\n",
    "    # Calculate average FPS for past frames\n",
    "    avg_frame_rate = np.mean(frame_rate_buffer)\n",
    "\n",
    "    if record:\n",
    "        recorder.write(frame)\n",
    "\n",
    "recorder.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5fa22a-f541-4a57-8652-83ee0748d5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pipeline FPS: 290.82\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "print(f'Average pipeline FPS: {avg_frame_rate:.2f}')\n",
    "if source_type == 'video' or source_type == 'usb':\n",
    "    cap.release()\n",
    "elif source_type == 'picamera':\n",
    "    cap.stop()\n",
    "if record: recorder.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
